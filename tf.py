# -*- coding: utf-8 -*-
"""tf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RwQrErCwUP0j07yCoj0HEy9jcrVjU-MQ
"""

from google.colab import drive
drive.mount('/content/drive')

from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from nltk.tokenize import word_tokenize
import pandas as pd
from sklearn.model_selection import train_test_split
import nltk
from nltk.corpus import stopwords
nltk.download('punkt')
nltk.download('stopwords')

mails = pd.read_csv("/content/drive/My Drive/spam_ham_dataset.csv", header=0)
mails.head()

import json
f = open('/content/drive/My Drive/cns/data.json',)
data = json.load(f)
f.close()

data_train, data_test, label_train, label_test = train_test_split(mails['text'], mails['label'],test_size=.10)

stop_words = set(stopwords.words('english'))

mail_vectors = []
count_list_train = []
for text, label in zip(data_train, label_train):
  mail_text = word_tokenize(text.lower())
  word_count={}
  ext_count=0
  for word in mail_text:
    if word in stop_words:
      continue
    if not word.isalpha():
      continue
    if len(word) <= 1:
      continue
    if word in data:
      if word in word_count.keys():
        word_count[word] += 1
      else:
        word_count[word] = 1
    else:
      ext_count=ext_count+1
  for item in data:
    if item not in word_count.keys():
      word_count[item]=0
  word_count = list(word_count.items())
  word_count.sort(key = lambda elem: elem[1], reverse=True)
  list1 = []
  for word in word_count:
    list1.append(word[1])
  list1.append(ext_count)
  mail_vectors.append(list1)

test_vectors = []
for text, label in zip(data_test, label_test):
  mail_text = word_tokenize(text.lower())
  word_count={}
  ext_count=0
  for word in mail_text:
    if word in stop_words:
      continue
    if not word.isalpha():
      continue
    if len(word) <= 1:
      continue
    if word in data:
      if word in word_count.keys():
        word_count[word] += 1
      else:
        word_count[word] = 1
    else:
      ext_count=ext_count+1
  for item in data:
    if item not in word_count.keys():
      word_count[item]=0
  word_count = list(word_count.items())
  word_count.sort(key = lambda elem: elem[1], reverse=True)
  list1 = []
  for word in word_count:
    list1.append(word[1])
  list1.append(ext_count)
  test_vectors.append(list1)

df = pd.DataFrame(data=mail_vectors)
df.head()

df_test = pd.DataFrame(data=test_vectors)
df_test.head()

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

rf = RandomForestClassifier(max_depth=10, random_state=0)
rf.fit(df,label_train)

lr = LogisticRegression(random_state=0).fit(df,label_train)

sv = SVC()
sv.fit(df,label_train)

test_predict_rf = rf.predict(df_test)
accuracy_score(test_predict_rf,label_test)

test_predict_lr = lr.predict(df_test)
accuracy_score(test_predict_lr,label_test)

test_predict_sv = sv.predict(df_test)
accuracy_score(test_predict_sv,label_test)